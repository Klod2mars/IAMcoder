meta:
  model: qwen2.5-coder:7b
  memory: config/memory_local/qwen_memory.yalm
  mission_id: setup_phase_01
  version: 1.0
  description: >
    Première mission d’amorçage AIHomeCoder.
    Teste le pipeline complet : lecture mémoire, exécution locale via Ollama, et génération d’un rapport Markdown.
    Doit créer un fichier de sortie et un .lialm d’échange.

intent:
  - Vérifier que la communication avec Qwen fonctionne via ai_interface.py.
  - Générer un rapport minimal en Markdown dans /reports/.
  - Créer un fichier d’échange .lialm pour DeepSeek dans /exchange/.

context:
  environment: ollama
  language: English
  mode: local_test
  output_format: markdown
  max_tokens: 2000

tasks:
  - "Read the memory file defined in meta.memory and include its context."
  - "Print system greeting: 'AIHomeCoder Local Mission Initialized'."
  - "Simulate a short analysis (3 bullet points) about Clean Architecture consistency."
  - "Save the result in /reports/mission_test_output.md."
  - "Generate an equivalent YAML exchange file /exchange/qwen_to_deepseek_test.lialm."

outputs:
  - format: markdown
    destination: reports/mission_test_output.md
  - format: lialm
    destination: exchange/qwen_to_deepseek_test.lialm
  - log: logs/mission_setup_phase_01.log

post_actions:
  - Validate that both output files exist.
  - Display the first 10 lines of the Markdown report in console.
  - Print confirmation message: "✅ AIHomeCoder setup phase complete."

